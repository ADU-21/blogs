---
title: 关于爬虫你不得不知道的几个库
date: 2016-04-02 10:21:33
categories: crawler
tags: [爬虫, python]
	
---
# 关于python爬虫
首先解释一下爬虫的原理，就是使用代码模拟浏览器动作通过HTTP协议远程和服务器进行交互，理论上只要是人能操作网站做的事情爬虫都可以做，比如登录，注册，获取信息，但是爬虫有两大壁垒，一个是IP禁止，一个是验证码，前一个基于网站的用户管理，后一个则基于高深莫测的图像识别（机器学习）。
除此之外，爬虫的优势是高效。
当然对于一些防御力比较低的网站是可以用爬虫进行攻击的，通过大量访问。不过这种攻击方式比较原始，而且没有技术含量。
爬虫主要还是被人们用以获取网络上的信息，该信息来自服务器，走的是HTTP协议。

关于HTTP协议我就不多说了，大家可以参考我的另一篇日志[HTTP协议详解](http://adu.404nf.cn/2016/03/30/HTTP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/)，下面我来说说实现爬虫的流程。
<!-- more -->
首先，爬虫要向服务器发送请求，如果请求返回200则可以提取出HTML代码，或json格式对象，或者是XML，就是我们浏览器接收到的代码（如果header配置和浏览器发出的请求header一致，返回的信息是相同的），前两种比较常见。得到服务器返回信息后我们需要进行处理，如果是json的话在python内直接用dict就可以处理了，如果是HTML则需要用到BeautifulSoup等解析工具，这里推荐使用lxml解析器，因为综合性能和易用性来看这是最优解，不要去纠结正则表达式xpath和那个什么pyQuera了，使用BeautifulSoup，支持python2和python3。
最后，对于了解过python的朋友，推荐使用gevent协程进行一个并发处理。
下面我一个个解释：
## requests
接触python的web应用不可不知的一个库，煞是强大，官方文档供参考：

[Requests: HTTP for Humans](http://docs.python-requests.org/zh_CN/latest/)

另外还有个高级用法：

[开发者接口](http://docs.python-requests.org/zh_CN/latest/api.html)

## BeautifulSoup
同样，没有什么比文档更好的解释：

[Beautiful Soup 4.2.0 文档](http://beautifulsoup.readthedocs.org/zh_CN/latest/)

## gevent
这个我没有看官方文档，我觉得这篇文章讲的就可以：

[gevent程序员指南](http://xlambda.com/gevent-tutorial/)

## 既然说到文档
不可不知的一个python文档而我却最近才知道的。。
python官方文档：

[python官方文档](http://python.usyiyi.cn/)

pip文档，分享给大家：

[pip](https://pip.pypa.io/en/stable/installing/)(可惜没有中文的)


## 最后是不是该还有个例子
等有空再写吧